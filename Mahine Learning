# Algoritmo De Clasificación
# Importando librerías
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# ----------------------------------
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.datasets import load_breast_cancer
# ----------------------------------
# import warnings
# warnings.filterwarnings('ignore') (ignorar algunos filtros de la data)

# Configurar estilos de los gráficos
plt.style.use('ggplot')
%matplotlib inline
# ---------------------------------
# 1. cargar y explorar los datos
print("=====1. cargando y explorando los datos===")
data = load_breast_cancer()
df=pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target
print("\nPrimeras 5 filas de dataset:")
print(df.head())
print("\nDescripción del dataset:")
print(df.describe())
print("\nInformación del dataset:")
print(df.info())
#Visualización de datos
print("\n=====2. Visualización de datos===")
plt.figure(figsize=(12,8))
sns.countplot(x='target', data=df)
plt.title('Distribución de casos (0: Maligno, 1: Benigno)')
plt.show()
# ---------------------------------
# Historial de las características
df.drop('target', axis=1).hist(bins=20, figsize=(20,15))
plt.suptitle('Distribución de características', y=1.02)
plt.show()
# Matriz de correlación
plt.figure(figsize=(12,10))
sns.heatmap(df.corr(), annot=False, cmap= 'coolwarm')
plt.title('matriz de correlación entre características')
plt.show()
# preprocesamiento de datos
print('n\====3. Preprocesamiento de datos===')
x=df.drop('target', axis=1)
y=df['target']
# Dividir en conjuntos de entrenamiento y prueba
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.3, random_state=42)
# Escalar características
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)
print('===SALIDAS===')
print(f'\n Forma de los datos de entrenamiento: {x_train.shape}')
print(f'Forma de los datos de prueba: {x_test.shape}')
# Entrenamietno del modelo
print('n\====4, Entrenamiento del modelo====')
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(x_train, y_train)
# Evaluación del Modelo
print('n\====5. Evaluación del modelo===')
y_pred = model.predict(x_test)
print('n\==Reporte de Clasificación: ')
print(classification_report(y_test, y_pred))
# ________________________________
# Las matrices de confusión son herramientas esenciales en el aprendizaje automático,
# especialmente para evaluar el rendimiento de modelos de clasificación. Permitem
# visualizar y analizar la precisión de las predicciones, identificando errores
# comunes y áreas donde el modelo necesita mejoras

print('\nMatriz de confusión: ')
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicciones')
plt.ylabel('Valores reales')
plt.title('Matriz de confusión')
plt.show()

# =================================
print(f'\nPrecisión del modelo: {accuracy_score(y_test, y_pred):.2f}')
# Importancia de las características
print('\n====6. Importancia de las características====')
feature_importance = pd.Series(model.feature_importances_, index=data.feature_names)
feature_importance.nlargest(10).plot(kind='barh', figsize=(10, 8))
plt.title('Importancia de las características')
plt.show()

# Predicción de Ejemplo
print('\n====7. Predicción de ejemplo====')
sample = x_test[0].reshape(1, -1)
prediction = model.predict(sample)
print(f"\nPredicción para el primer ejemplo: {'Benigno' if prediction[0] == 1 else 'Maligno'}")
